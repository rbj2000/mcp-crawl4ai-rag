# Staging Environment - Production-like Testing
# =============================================

# Server Configuration
HOST=0.0.0.0
PORT=8051
TRANSPORT=sse
ENVIRONMENT=staging

# AI Provider Configuration - Test both providers
AI_PROVIDER=${AI_PROVIDER:-ollama}
EMBEDDING_PROVIDER=${EMBEDDING_PROVIDER:-ollama}
LLM_PROVIDER=${LLM_PROVIDER:-ollama}

# OpenAI Configuration
OPENAI_API_KEY=${OPENAI_API_KEY}
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
MODEL_CHOICE=gpt-4o-mini

# Ollama Configuration
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
OLLAMA_LLM_MODEL=llama3.2:1b
OLLAMA_EMBEDDING_DIMENSION=768
EMBEDDING_DIMENSION=768

# Database Configuration - Staging database
VECTOR_DB_PROVIDER=supabase
SUPABASE_URL=${SUPABASE_STAGING_URL}
SUPABASE_SERVICE_KEY=${SUPABASE_STAGING_KEY}

# RAG Strategy Configuration - Production-like
USE_CONTEXTUAL_EMBEDDINGS=true
USE_HYBRID_SEARCH=true
USE_AGENTIC_RAG=true
USE_RERANKING=false
USE_KNOWLEDGE_GRAPH=false

# Performance Configuration - Production-like but smaller
MAX_CONCURRENT_REQUESTS=8
BATCH_SIZE=25
CACHE_TTL=1800  # 30 minutes
EMBEDDINGS_BATCH_SIZE=10

# Security Configuration - Production-like
CORS_ORIGINS=https://staging.yourdomain.com
RATE_LIMIT_PER_MINUTE=200
MAX_CONTENT_LENGTH=10485760  # 10MB

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=/app/logs/staging.log
ENABLE_METRICS=true

# Health Check Configuration
HEALTH_CHECK_INTERVAL=30
HEALTH_CHECK_TIMEOUT=10
HEALTH_CHECK_RETRIES=3

# Docker Compose Profiles
COMPOSE_PROFILES=ollama,monitoring

# Staging-specific Features
ENABLE_DEBUG_ENDPOINTS=true
ENABLE_SWAGGER_UI=true
ENABLE_LOAD_TESTING=true

# Testing Configuration
AUTOMATED_TESTING=true
PERFORMANCE_TESTING=true
INTEGRATION_TESTING=true

# Monitoring Configuration
PROMETHEUS_ENDPOINT=http://prometheus:9090
GRAFANA_ENDPOINT=http://grafana:3000
ENABLE_TRACING=true

# Data Lifecycle
DATA_RETENTION_DAYS=7
AUTO_CLEANUP=true
CLEANUP_SCHEDULE="0 1 * * *"  # Daily at 1 AM